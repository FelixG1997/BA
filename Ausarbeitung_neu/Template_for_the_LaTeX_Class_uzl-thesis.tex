\documentclass[german,version-2019-11]{uzl-thesis}
\UzLThesisSetup{
  Logo-Dateiname        = {uzl-thesis-logo-itcs.pdf},
  Verfasst              = {am}{Institut für Theoretische Informatik},
  %
  % The titles:
  %
  Titel auf Deutsch     = {
    Algorithmen für bewegende Ziele im Travelling Salesman Problem
  }, 
  Titel auf Englisch    = {
    Algorithms for Moving-Target Travelling Salesman Problem
  },
  Autor                 = {Felix Greuling},
  Betreuerin            = {Prof. Dr. Maciej Liskiewicz},
  Bachelorarbeit,
  Studiengang           = {Informatik},
  Datum                 = {29. Dezember 2019},
  Abstract              = {
    \textcolor{red}{TODO}
    
  },
  Zusammenfassung       = {
    \textcolor{red}{TODO}  
  },
  %Acknowledgements      = {}, 
  % Alphabetische Bibliographie
  % Alternatively:
  Numerische Bibliographie
}

% \UzLStyle{pagella basic design}
% \UzLStyle{pagella centered design}
% \UzLStyle{pagella contrast design}
% \UzLStyle{alegrya basic design}
% \UzLStyle{alegrya scholary design}
% \UzLStyle{alegrya stylish design}
\UzLStyle{alegrya modern design}
% \UzLStyle{thesis black and white structure}

% Now, include the package you need here using \usepackage. 
% \usepackage{graphicx,float,wrapfig}
\usepackage{mathtools}
\usepackage{algorithm}
\usepackage{algpseudocode}

%tikz
\tikzstyle{gray}  = [thick, color=gray, circle, draw]
\tikzstyle{red}   = [thick, color=red, circle, draw]
\tikzstyle{blue}  = [thick, color=blue, circle, draw]
\tikzstyle{green} = [thick, color=green, circle, draw]

\newtheorem{lem}{Lemma}

% begin of the document
\begin{document}
% \chapter{Introduction}
\chapter{Einleitung}

\textcolor{red}{TODO: Motivationseinleitung in das Thema}


%\section{Contributions of this Thesis}
\section{Beiträge dieser Arbeit}

In dieser Arbeit wird ein neuer auf dem eindimensionalen Moving-Target-Travelling-Salesman-Problem basierender Fall eingeführt. Dieser enthält zusätzlich eine weitere orthogonale Achse, auf welchem sich die Ziele und die Verfolger bewegen können. Die für den 1D-Fall bereits gezeigten Eigenschaften, dass der Verfolger in einer optimalen Tour sich jederzeit mit $v_{max}>v_i,~\forall v_i\in V$ bewegt und erst seine Richtung ändern kann, sofern er das schnellste Ziel in seiner Richtung eingeholt hat, gelten auch für diese neue Modifikation. Mit dem Prioritätsalgorithmus wurde ein effizienter aber nicht optimaler Algorithmus vorgestellt, während der Brute-Force-Ansatz für optimale Ergebnisse bei kleinen Instanzen genutzt werden kann. \\
\textcolor{red}{TODO: Ergebnisse aus Experimente präsentieren}


%\section{Related Work}
\section{Verwandte Arbeiten}

Im Jahre 1998 wurde diese spezielle Instanz des Travelling-Salesman-Problem vorgestellt\cite{helvig}. Dabei wurde dynamische Programmierung in Kombination mit der Modellierung eines Graphen in topologischer Reihenfolge als Strategie für eindimensionale Moving-Target-TSP vorgeschlagen. Diese besitzt eine Zeitkomplexität von $\mathcal{O}(n^2)$. Die Approximation für generelle Fälle gilt dabei schwierig, da viele verschiedene Faktoren die Komplexität des Problems bestimmen. Die Approximations-Forschung in \cite{hammar} zeigte, dass sich die Probleme nicht besser als mit einem Faktor von $2^{\pi(\sqrt{\pi})}$ in polynomieller Zeit lösen lassen, es sei denn es gilt $P=NP$. Dies gilt bisher allerdings weiterhin als ungelöstes Problem in der Informatik. In jedem Fall gelten Moving-Target-TSP als NP-hart, selbst wenn sich nur zwei Ziele bewegen\cite{hammar}.\\


%\section{Structure of this Thesis}
\section{Aufbau dieser Arbeit}
Diese Arbeit beschreibt zunächst in Kapitel 2 die vorangegangenen Forschungen des eindimensionalen Moving-Target-TSP. Dabei wird speziell die Modellierung und der dazu entwickelter Algorithmus erläutert. Anschließend wird in Kapitel 3 ein neuer Fall vorgestellt. Dafür wird der 1D-Fall um eine orthogonale Achse erweitert, auf der sich die Ziele sowie der Verfolger bewegen können. Für den neuen Fall werden theoretische Eigenschaften gezeigt, die auch für den 1D-Fall gelten. So wird in Kapitel 4 ein Prioritäts- und Brute-Force-Algorithmus präsentiert. Zuletzt folgt in Kapitel 5 ein Experimentierteil für alle drei Algorithmen inklusive der Bestimmung der Güte.

%--------------------------------------------------------------------------------------

\chapter{Grundlagen}
\label{chapter-use}
Im folgenden Kapitel werden alle nötigen Grundlagen für das Moving-target Traveling Salesman Problem (MT-TSP)\footnote{zu Deutsch: bewegende Ziele im Travelling Salesman Problem} erläutert. Beim herkömmlichen Travelling Salesman Problem wird eine optimale Tour durch alle Ziele und Rückkehr zum Startpunkt gesucht. Diese ist die kürzeste Reihenfolge an Zielen, bei dem jedes $z_i\in Z$ abgefangen wurde. Dabei startet und beendet der Verfolger jede Tour im Ursprung. Das MT-TSP ist eine spezielle Instanz des TSP mit der Erweiterung, dass die Ziele nicht mehr stationär sind, sondern eine konstante Bewegung haben.


\section{Eindimensionaler Fall im MT-TSP}
Der eindimensionale Fall (1D-Fall) des MT-TSP wurde das erste Mal in \cite{helvig} erwähnt und stellt die Grundlage dieser Arbeit dar. Dabei sind jegliche Bewegungen der Ziele und des Verfolgers auf eine Linie beschränkt. 
\begin{definition} 
\label{def:Instanz}
Jede Instanz $I$ im 1D-Fall des MT-TSP enthält eine Anzahl $n$ von Zielen $Z = \{z_1,...,z_n\}$ und den Verfolger $\kappa$. $I$ wird demnach beschrieben durch
\begin{align*}
I = (Z, \kappa).
\end{align*}
Jedes Ziel $z_i$ befindet sich zunächst an einem Startpunkt $p_i$ und bewegt sich dann mit einer konstanten Geschwindigkeit $v_i$ entlang einer Achse , $p_i, v_i \in\mathbb{R}$. Demnach kann ein Ziel als ein Tupel $z_i = (p_i, v_i)$ dargestellt werden. Der Ursprung ist der Start und das Ziel jeder Tour und ist definiert durch einen Punkt ohne Geschwindigkeit. Die genaue Position ist dabei die Startposition des Verfolgers $p_{\kappa}$. Jegliche Positionen und Geschwindigkeiten können dabei als Vektoren $P$ und $V$ 
\begin{align*}
P &= (p_1, ..., ,p_n)\\
V &= (v_1,\; ...,\; v_n)
\end{align*}\newpage\noindent
dargestellt werden.
\end{definition}\noindent
Das Tupel $(-1,0)$ würde also als Beispiel bedeuten, dass der Verfolger an der Koordinate $-1$ startet und ist durch die Geschwindigkeit von $0$ stationär. Einfachheitshalber wird in dieser Arbeit der Ursprung mit $(0,0)$ für 1D-Fälle fest definiert. Ein Ziel mit einer negativen Koordinate befindet sich auf der linken, positive Koordinaten auf der rechten Seite des Ursprungs. 

\begin{definition}
Der Verfolger bewegt sich mit der Maximalgeschwindigkeit 
\begin{align*}
v_{verfolger} > |v_i|, \forall v_i\in V,
\end{align*}
somit wird sichergestellt, dass der Verfolger nach einer gewissen Zeit jedes Ziel auf jeden Fall eingeholt hat.
\end{definition} \noindent
Ohne diese Definition ist es möglich, dass eine unendlich große Tourzeit berechnet wird, da einige Ziele nicht abgefangen werden können.

\begin{definition}
\label{def:UpdatedPos}
Mit dem Zeitstempel $t\in \mathbb{R}^+_0$ kann genau bestimmt werden, an welcher Position sich ein Ziel hinbewegt hat. Die Position eines Ziels ist also abhängig vom aktuellen Zeitstempel $t$. Jede Tour beginnt bei $t=0$. \\
Es gilt
\begin{align*}
p_{i,t} = p_{i,0} + v_i\cdot t.
\end{align*} 
\end{definition}

\begin{definition}
\label{def:WegZeit}
Die Zeit, die benötigt wird, um ein Ziel $B$ von der Position von Ziel $A$ einzuholen, ist als. 
%v_{verfolger}\cdot\tau + pos_A &= v_{B}\cdot\tau + pos_B \\
%(v_{verfolger}-v_B)\cdot\tau &= pos_B-pos_A \\
\begin{align*}
\tau &= \bigg\vert\frac{\|pos_A,pos_B\|_1}{v_{verfolger}-v_B}\bigg\vert
\end{align*} 
definiert.
\end{definition}\noindent
Die Berechnung beruht auf der nach der Zeit (in diesem Fall $\tau$) gleichgesetzten und umgestellten physikalischen Formel \footnote{Gleichförmige Bewegung: $s=v\cdot t+s_0$}.
Bemerke, $v_A$ wird durch $v_{verfolger}$ ersetzt, da sich der Verfolger immer mit maximaler Geschwindigkeit bewegt.\\
Mit diesen Voraussetzungen kann da Problem nun modelliert und gelöst werden. Dafür wird im Folgenden die Vorarbeit aus \cite{helvig} detailliert beschrieben. Die Autoren modellieren das Problem als Graph-Problem, wobei der eigentliche Graph on-the-fly erstellt wird. Mit linearer Programmierung wird anschließend die schnellst mögliche Abfangzeit für jeden Zustand bestimmt. Somit kann die die optimale Tourzeit und -Reihenfolge bestimmt werden.
Im eindimensionalen Fall befinden sich alle Ziele auf einer Achse und können sich nur in zwei verschiedene Richtungen bewegen. Dasselbe gilt auch für den Verfolger. Wichtig ist zunächst die Bedingung, dass der Verfolger sich immer mit seiner maximalen Geschwindigkeit $v_{verfolger}$ bewegt. Helvig et. al. bewiesen dies mit dem Aspekt, dass ein eine Reisegeschwindigkeit von $v<v_{verfolger}$ äquivalent zu einer Wartezeit an einem Punkt ist. Dies resultiert in eine längere Tourzeit, das heißt die Tour wäre nicht mehr optimal.\\
Um das Problem der kürzesten Route zu lösen, muss sich der Verfolger an einem Ziel entscheiden, das nächste Ziel in derselben oder entgegengesetzte Richtung einzuholen. Die Kostenberechnung für eine schnellste Tour aus
\begin{itemize}
\item alle Ziele links vom Ursprung aus gesehen und danach alle rechten Ziele abfangen
\item alle Ziele rechts vom Ursprung aus gesehen und danach alle linken Ziele abfangen
\end{itemize} 
ist zwar simpel und einfach implementierbar, reicht aber nicht aus (siehe Abbildung \ref{fig:GegenBsp1Dim}).
\begin{figure}[htbp]
\centering
\includegraphics[scale=0.68]{../Grafiken/Verwendete/1DGegenbsp.PNG}
\caption{Offensichtlich würde der Verfolger mit der Geschwindigkeit $v_{verfolger}=11$ deutlich länger für eine Tour brauchen, sofern er zunächst alle Ziele auf der einen und dann auf der anderen Seite abarbeitet. Hierbei wäre es sinnvoll, zunächst die Ziele $(-1,-10)$ und $(1,10)$ einzuholen.}
\label{fig:GegenBsp1Dim}
\end{figure}
Im worst case geht $t\rightarrow\infty$, sobald die äußersten Ziele noch deutlich weiter entfernt vom Ursprung aus liegen. Die Autoren aus \cite{helvig} definierten daraufhin Wendepunkte und bewiesen ihre Korrektheit. Nur an diesen ist es dem Verfolger möglich, die Richtung zu ändern. Wendepunkte sind dabei die schnellsten Ziele auf der rechten bzw. rechten Seite des Verfolgers. Sofern der Verfolger vor einem Wendepunkt umkehrt, verlängert sich die Tour und ist damit nicht mehr optimal.
\begin{definition}
Ein Zustand $A$ ist definiert durch die aktuelle Position des Ziels ($s_k$), an dem sich der Verfolger zur Zeit befindet und dem schnellsten Ziel auf der gegenüberliegenden Seite des Ursprungs ($s_f$). Es ist also wieder eine Tupeldarstellung
\begin{align*}
A = (s_k, s_f)
\end{align*}
möglich, wobei $s_k$ und $s_f$ wiederum Tupel sind (siehe Definition \ref{def:Instanz}).
\end{definition}\noindent
Ein Zustand stellt eine Momentaufnahme der Tour dar. Dabei wird ein potentieller Wendepunkt repräsentiert. Um die optimale Tour zu bestimmen, muss an jedem dieser Punkte korrekt entschieden werden, ob sich der Verfolger weiter in die Richtung bewegt oder $s_f$ auf der anderen Seite des Ursprungs verfolgt. Im Gegensatz zu den anderen Zuständen besitzen $A_0$ und $A_{final}$ keine Tupel. Dabei handelt es sich um den Start und Endzustand, welche bei jeder Tour gleich sind. Der Verfolger befindet bei beiden dieser Zuständen im Ursprung. 
Mit der Funktion $t$ wird einem Zustand die aktuell minimale Zeit zugewiesen, mit der der Zustand über andere Zustände bis dahin am schnellsten erreichbar ist (siehe Definition \ref{def:UpdatedPos}). Offensichtlich gilt demnach $t[A_0] = 0$. \\
Wie bereits erwähnt, gibt es in den meisten Fällen Ziele, welche keine potentiellen Wendepunkte darstellen und somit nicht zur optimalen Tour beitragen. Um die Laufzeit und Speicherkomplexität zu reduzieren, können diese zunächst eliminiert werden. Es handelt sich dabei um Ziele, die sowieso eingeholt werden. Zunächst wird jedes Ziel in die Liste \emph{Left} oder \emph{Right} eingefügt, abhängig davon, ob sich das Ziel bei $timestamp = 0$ auf der linken oder rechten Seite des Ursprungs befindet. Anschließend werden \emph{Left} und \emph{Right} in absteigender Reihenfolge nach den Geschwindigkeiten sortiert. Ziele, welche sich nun näher am Ursprung befinden
und zugleich langsamer sind als ein anderes aus der jeweiligen Liste, werden eliminiert. Damit beinhalten \emph{Left} und \emph{Right} ausschließlich potentielle Wendepunkte. \\
Um nun alle Zustände zu bestimmen, wird jede Kombination aus den Listen \emph{Left} und \emph{Right} und umgekehrt für $s_k$ und $s_f$ eingesetzt und in die Zustandsliste $States$ eingefügt. Anschließend wird $States$ in absteigender Reihenfolge nach der Summe der Indizes der Ziele aus den Listen \emph{Left} und \emph{Right} sortiert (siehe Abbildung \textcolor{red}{TODO: Bsp mit den Zielen aus der Abbildung 2.1}). Somit befinden sich die Kombinationen bzw. Zustände aus den schnellsten Zielen am Listenanfang von $States$.\\
Ein Zustandsübergang von Zustand A in den Zustand B wird mit
\begin{align*}
\tau = A\rightarrow B
\end{align*}
beschrieben. Der Übergang $\tau$ gibt dabei die Zeit $\tau$ (siehe Definition \ref{def:WegZeit}), um von dem aktuellen Zustand $A$ in den nächsten Zustand $B$ zu gelangen). Ausgehend von einem Zustand, gibt es bis zu zwei Zustandsübergänge. Dabei handelt es sich von dem nächst-schnellsten auf der linken oder rechten Seite des Ursprungs. Die Übergänge werden dann als $\tau_{left}$ und $\tau_{right}$ bezeichnet. Sofern jedes Ziel auf einer Seite eingeholt wurde, wird der Übergang $\tau_{final}$ in $A_{final}$ gewählt. Für die Berechnung von $\tau_{final}$ wird die Zeit vom aktuellen Zustand bis zum Abfangen der restlichen Ziele auf der anderen Seite des Ursprungs und zusätzlich die Rückkehr zum Ursprung berechnet. Offensichtlich existiert eingehend in $A_0$ und ausgehend von $A_{final}$. \\
Wie bereits erwähnt, ist die Zustandsliste $States$ nach der Summe der Indizes aus \emph{Left} und \emph{Right} in absteigender Reihenfolge sortiert. Mit zwei Möglichkeiten von $\tau_{Left}$ und $\tau_{right}$ führt jeder Zustand in einen anderen Zustand mit einem höheren Index. Dabei erhält der Startzustand $A_0$ die Summe $-1$, wodurch die Zustandsübergänge in die Zustände mit dem Summenwert von $0$ führen. Die Zustände mit der höchsten Summe führen in $A_{final}$ (Dies gilt sowieso mit der vorherigen Regelung). Mit diesen Bedingungen konnte nun aus $States$ ein Graph $G$ erzeugt werden. Anhand der Abbildung 2.3 (siehe Abbildung \textcolor{red}{TODO: Bsp mit der Abbildung 2.2}) ist diese Modellierung anhand des bisherigen Beispiels aus Abbildung 2.1 und 2.2 gut nachvollziehbar. Im Graph
\begin{align*}
G = (V,E)
\end{align*}
werden die Knoten $V$ durch die Zustände $A_i \in States$ und $E$ durch die jeweiligen Zustandsübergänge $\tau$ repräsentiert. Mit der Bedingung, dass Übergänge nur in Zustände mit höheren Summenwerten führen, ist $G$ gerichtet und azyklisch. Man gelangt also nach spätestens $n$ Zuständen (exklusive $A_0$) in $A_{final}$. \\
Mit der Modellierung des Problems als Graphen und den Eigenschaften, dass dieser azyklisch und in topologischer Reihenfolge sortiert ist, kann das Problem mit einem einfachen \emph{Kürzeste-Wege}-Algorithmus gelöst werden. Hierbei kann eine simple Heuristik, zum Beispiel \cite{brandstadt1994kurzeste}, verwendet werden, um den kürzesten Weg von $A_0$ nach $A_{final}$ zu bestimmen.\\
Mit der Bestimmung des kürzesten Pfades muss am Ende noch bestimmt werden, welche Ziele zwischen den Zuständen eingeholt wurden. Damit werden die anfangs eliminierten Zustände wieder der Tour hinzugefügt und bestenfalls (richtige Implementierung) ist somit die optimale Tour bestimmt.

\subsection{Algorithmus von Helvig, Robins and Zelikovsky}

Mit diesen Voraussetzungen haben die Autoren von \cite{helvig} einen exakten $\mathcal{O}(n^2)$-Algorithmus für eindimensionale Fälle entwickelt, welcher auf dynamischer Programmierung basiert. Dieser bestimmt dabei die optimale Tour für die Eingabeinstanz. \\
Nach dem Schema aus dem vorherigen Abschnitts werden wieder die Listen \emph{Left}, \emph{Right} und $States$ generiert. Anschließend wird durch jeden der $n^2$ Zustände iteriert. Für das einfachere Verstehen des Algorithmus wurde der Graph $G$ zwar beschrieben, aber nicht generiert. Somit wird der Speicherplatz reduziert und damit die Effizienz des Algorithmus verbessert. Diese \emph{On-the-fly}-Methode, um den Graph $G$ zu generieren, ist durch die topologische Sortierung möglich. Damit ist für jeden Zustand sichergestellt, dass dieser mit minimaler Zeit erreicht wurde. Zudem ist nicht für jeden Zustand eine Berechnung der Übergänge in andere Zustände nötig. Einige werden ausgelassen oder führen direkt in $A_{final}$. Dies lässt sich auf das Vorgehen des Algorithmus zurückführen. Für einen Zustand $A_i$ wird dabei eines der folgenden Schritte ausgeführt:
\begin{itemize}
\item Wenn in $A_i$ keine eingehenden Übergänge besitzt, führe mit dem nächsten Zustand in der Liste fort. Dies tritt genau dann auf, wenn $t[i] = \infty$.
\item Falls der Verfolger jedes Ziel auf einer Seite des Ursprungs eingeholt hat, erzeuge einen Übergang $\tau_{final}$ in $A_{final}$. Berechne die Zeit, um die verbleibenden Ziele auf der anderen Seite einzuholen und zusätzlich die Retour zum Ursprung. 
\item Berechne ansonsten $\tau_{Left}$ und $\tau_{Right}$, welche den Verfolger entweder zum schnellsten Ziel auf der rechten oder linken Seite schickt. Falls die Zeit addiert mit dem aktuellen Zeitstempel $t[i]$ kleiner ist, als bisher von einem anderen Zustand, aktualisiere $t[A_{Left}]$ bzw. $t[A_{Right}]$ mit diesem Wert.
\end{itemize}
Schließlich werden alle Ziele, einschließlich der zuvor eliminierten Ziele, zwischen den Wendepunkten berechnet und in der richtigen Reihenfolge zusammengefügt. Somit wird eine optimale Tour durch die Kombination aus topologischer Reihenfolge und linearer Programmierung garantiert.
\textcolor{red}{TODO: Algorithmus von Helvig selber aufschreiben}

\section{Input $\&$ Output}

Um Heuristiken aufzustellen und zu bewerten ist ein sinnvoller und einheitlicher Input und Output notwendig. Für den Input wird eine Menge $T$ von Zielen sowie die initiale Position und Geschwindigkeit des Verfolgers erwartet. Dies reicht aus, um eine Tour zu bestimmen. \\
Beim Output kommt es darauf an, wie detailliert die Tour beschrieben werden soll. Als offensichtliche Parameter werden die Tourlänge und Tourzeit zurückgegeben. Damit ist allerdings die Tour schlecht nachvollziehbar. Demnach werden die Ziele in der vom Verfolger eingeholten Reihenfolge zurückgegeben. Dabei verfügt jedes Ziel über die Position und Zeit in der der Verfolger es eingeholt hat. Um die Tour komplett nachvollziehen, ist eine graphische Anwendung sinnvoll, aber nicht notwendig. \\
Die Algorithmen dieser Arbeit werden dabei einfach nur die Ziele in der eingeholten Reihenfolge zurückgeben. Je nach Implementierung kann dann einem Ziel dabei die eingeholte Zeit zugeordnet werden, womit man dann anschließend alle restlichen Informationen berechnen kann. \\
Sobald allerdings eine ungültige Eingabe, z.B. wenn eine Zielgeschwindigkeit größer als die Verfolgergeschwindigkeit ist, wird eine \glqq Nein\grqq-Instanz zurückgegeben. Dies wird allerdings in den Algorithmen vorausgesetzt und nicht extra behandelt. 

\chapter{Zwei-orthogonale-Achsen im MT-TSP}

Als neue Modifikation des 1D-Falls wird nun der Achse eine weitere hinzugefügt. Alle Bewegungen und Positionierungen der Ziele und des Verfolgers sind ebenfalls auf die Achsen beschränkt. Die Achsen liegen dabei orthogonal zueinander. Den Ziele ist es dabei nicht erlaubt, an dem Schnittpunkt die Achse zu wechseln. Ein Ziel befindet sich also entweder auf der waagerechten oder senkrechten Achse. Der Schnittpunkt ist dabei festgesetzt auf die Koordinate $0$, während der Ursprung, im Gegensatz zum 1D-Fall\footnote{Im 1D-Fall ist der Ursprung fest definiert auf die Koordinate $0$}, auf einer der Achsen liegen kann.\\
Mit der neuen Achse könnte für die Positionsbestimmung eine zweidimensionale Koordinate verwendet werden. Allerdings wäre einer dieser Koordinaten immer gleich $0$, da jegliche Bewegungen der Ziele und des Verfolgers auf die Achsen beschränkt sind. Somit ist nur eine einfache Ergänzung der Definition \ref{def:Instanz} um einen booleschen Wert $b$ nötig. Die Position $p_i$ wird dabei mit 
\begin{align*}
p_i = (a, b) ~|~a\in\mathbb{R}, b\in \{true, false\}
\end{align*}
neu definiert. Dabei gibt $b$ die Achse an, \emph{true} steht für die waagerechte, \emph{false} für die senkrechte Achse. Die Ziele werden nun neben den Listen \emph{Left} und \emph{Right} auch in die \emph{Top} und \emph{Bottom} einsortiert. Dabei deckt \emph{Top} den positiven und \emph{Bottom} den negativen Koordinatenbereich ab. Mit dieser Ergänzung gelten weiterhin alle anderen der vorherigen Definitionen.

\section{Theoretische Grundlagen}

In diesem Abschnitt soll mit der Vorarbeit aus \cite{helvig} gezeigt werden, dass einige Eigenschaften des 1D-Falls genauso auch im zwei-orthogonale-Achsen-Fall des MT-TSP gelten.

\begin{lem}
\label{lem:1}
In jeder optimalen Tour bei zwei orthogonale Achsen im MT-TSP bewegt sich der Verfolger immer mit maximaler Geschwindigkeit.
\end{lem}
 
\begin{proof}
Der Beweis basiert darauf, dass in jedem Fall eine Reduzierung auf den Beweis von \cite{helvig} vorgenommen wird. Dafür nehmen wir eine Fallunterscheidung vor:
\begin{enumerate}
\item Das nächste Ziel des Verfolgers liegt auf der selben Achse: \\
Mit dem Beweis für 1D-Fälle in \cite{helvig} gilt dies unmittelbar auch für diesen Fall.

\item Das nächste Ziel des Verfolgers bewegt sich auf der anderen Achse: \\
Indirekter Beweis: \\
Nehmen an, der Verfolger bewegt sich mit $v_{verfolger} < v_{max}$. Dies ist äquivalent dazu, dass der Verfolger an seiner aktuellen Position eine Zeit $\tau$ wartet und sich dann mit $v_{max}$ weiterbewegt, um dann das nächste Ziel $s$ einzuholen. Dabei befindet sich $s$ auf der anderen Achse. Nach der Wartezeit erreicht der Verfolger an Zeitpunkt $t_1$ den Schnittpunkt und holt das Ziel $s$ an der Position $p$ zum Zeitpunkt $t_2$ ein. \\
Nehmen nun an, dass der Verfolger sich direkt zum Mittelpunkt bewegt. Bis zum Eintreffen des Zeitpunktes $t_1$ wartet der Verfolger nun wieder die Zeit $\tau$. Das Ziel $s$ wird nun zum selben Zeitpunkt $t_2$ bei $p$ erreicht, wie im vorherigen Szenario. \\
Dies wird nun fortgeführt, indem der Verfolger nicht im Schnittpunkt wartet, sondern von diesem aus $p$ direkt erreicht. Bis zum Zeitpunkt $t_2$ wird nun wieder für die Dauer von $\tau$ gewartet. Außerdem kann der Verfolger schon zu einem Zeitpunkt $t_1 \leq t_{s} \leq t_2$ abfangen, sofern sich $s$ vom Verfolger wegbewegt. \\
Wird dies nur für alle restlichen Ziele der Tour fortgeführt, resultiert dies letztendlich in Wartezeit am Ende der Tour, was offensichtlich nicht optimal ist. Dieser Fall ist demnach nur eine Erweiterung des 1D-Fall-Beweises um den Schnittpunkt zwischen Zielen, die auf unterschiedlichen Achsen liegen. 
\end{enumerate}

In jedem der Fälle wird eine Wartezeit erzeugt, welche an das Ende der Tour \\verschoben werden kann. Somit ist die Tour offensichtlich nicht mehr optimal. Der Verfolger bewegt sich also zu jeder Zeit mit $v_{verfolger} = v_{max}$.
\end{proof}

\begin{lem}
In jeder optimalen Tour bei zwei orthogonale Achsen im MT-TSP kann der Verfolger erst seine Richtung ändern, wenn er das schnellste Ziel in seiner Richtung abgefangen hat.
\end{lem}

\begin{proof}
Für den Beweis des Lemmas müssen drei Fälle betrachtet und bewiesen werden.\\
Fallunterscheidung:\\
\begin{enumerate}
\item Der Verfolger bewegt sich vom Ursprung weg in Richtung des schnellsten Ziels $s$ auf der selben Achse: \\
Mit dem Beweis für 1D-Fälle in \cite{helvig} gilt dies unmittelbar auch für diesen Fall. Dies gilt für jede Seite jeder Achse, auf der sich der Verfolger vom Ursprung wegbewegt.

\item Der Verfolger hat soeben das schnellste Ziel auf einer Achse abgefangen und bewegt sich nun zum nächsten Ziel, welches zwischen dem so eben abgefangenen Ziel und dem Schnittpunkt liegt:\\
Dies erweitert den 1. Fall nur um die Richtung des Verfolgers und ist damit ebenfalls mit dem Beweis aus \cite{helvig} gezeigt.

\item Der Verfolger hat soeben das schnellste Ziel auf einer Achse abgefangen und bewegt sich nun zum Schnittpunkt:\\
Nach \cite{helvig} kann sich nun der Verfolger nicht umdrehen und ein anderes Ziel auf der Achse einholen. Damit hätte er eine Zeit lang nicht das schnellste Ziel einer Richtung eingeholt und somit nach \cite{helvig} äquivalent zum Warten in einem Punkt ist. Dies resultiert nach Lemma \ref{lem:1} in eine nicht optimale Tour.\\
Sei der Verfolger nun am Schnittpunkt angekommen. Dieser hat nun drei Richtungsmöglichkeiten. Dabei spielt es allerdings keine Rolle für welche der drei Richtungen sich der Verfolger entscheidet, denn ab dem Schnittpunkt gilt für jede der Richtungen wieder der 1. Fall.
\end{enumerate} \noindent
Es reicht also wieder aus, den 1D-Fall-Beweis für Wendepunkte aus \cite{helvig} als Grundlage für den zwei-orthogonale-Achsen-Fall-Beweis zu verwenden.
\end{proof}


\chapter{Heuristiken für zwei-orthogonale-Achsen im MT-TSP}

In diesem Kapitel werden konkrete Heuristiken für den zwei-orthogonale-Achsen-Fall präsentiert. Zunächst wird der Prioritätsansatz erläutert. Anschließend wird eine Verbesserung dieses Ansatzes betrachtet. Zuletzt wird die Brute-Force Methode vorgeschlagen. In jedem der Fälle werden die Laufzeit und Güte analysiert und die Korrektheit gezeigt.

\section{Problem der Modellierung bei zwei orthogonale Achsen im MT-TSP mit Zuständen als Graphen}
Im 1D-Fall konnte über über die topologische Reihenfolge der Wendepunkte bzw. Zustände ein Graph erzeugt werden. Somit wurde mit der Bestimmung des kürzesten Pfads das Problem die optimale Tour bestimmt. \\
Es wäre also zunächst sinnvoll, diesen Ansatz für den zwei-orthogonale-Achsen-Fall zu übernehmen, da nur eine Achse hinzugekommen ist. Hierfür werden wieder die einzelnen Ziele in die Listen \emph{Left, Right, Top} und \emph{Bottom} aufgeteilt. Bei dem Algorithmus von \cite{helvig} wurden nun die Ziele eliminiert, welche sowieso eingeholt werden und dementsprechend keine Wendepunkte darstellen. Mit der zusätzlichen Achse gilt dies nur noch für Ziele, welche sich wegführend vom Schnittpunkt bewegen. Das liegt daran, dass Ziele nun den Schnittpunkt überqueren können, während der Verfolger sich auf der anderen Achse befindet. Somit werden solche Ziele nicht automatisch eingeholt. \\
Der nächste Schritt ist nun die Generierung der Zustandsliste $States$, wobei eine Reihe von Problemen auftreten. Die Ziele befinden sich dabei im Laufe der Zeit nicht mehr unbedingt auf der Seite des Verfolgers, welche die jeweilige Liste aus \emph{Left, Right, Top} und \emph{Bottom} vorgibt. Sei der Verfolger zum Zeitpunkt $t$ auf der oberen Seite der senkrechten Achse. Das Ziel $z$ befindet sich in der Liste $Left$ und befindet zum Zeitpunkt $t$ auf der rechten Seite der waagerechten Achse. Damit befindet sich $z$ nun auch auf der rechten Seite des Verfolgers und ist nicht mehr repräsentativ für die Liste $Left$. \\
Mit dieser Überlegung muss nun jedes solcher Ziele, die den Schnittpunkt überqueren, betrachtet werden. Dieses hat potentiell eine hohe Geschwindigkeit und muss somit ggf. möglichst schnell abgefangen werden. Problematisch ist dabei, dass ein Ziel vielleicht eine hohe Geschwindigkeit besitzt, aber noch sich sehr weit entfernt vom Schnittpunkt befindet. (siehe Abbildung \textcolor{red}{TODO}). Es müsste also für jegliche Ziele, die einen Schnittpunkt überqueren extra Zustände geben, da diese als die nächsten Wendepunkte in Betracht gezogen werden könnten. Demnach gäbe es von einem Zustand weitaus mehr Übergänge, als nur $\tau_{left}$, $\tau_{right}$, $\tau_{top}$ und $\tau_{bottom}$. \\
Die nächste Überlegung wäre nun, die Listen nach jeder Iteration zu aktualisieren. Das Problem ist hierbei, dass damit die Modellierung des Graphen so nicht mehr funktioniert. Dabei entsteht mitten im Graphen ein komplett neuer Graph.  \\
Letztendlich würde ein optimaler Algorithmus eine sehr große Laufzeit benötigen und gerade bei vielen Randbedingungen ist eine korrekte Implementierung schwer. Daher wird im nachfolgenden Abschnitt ein anderer Ansatz, bei dem die Ziele nach einer Priorität abgefangen werden, mit der Laufzeitkomplexität von $\mathcal{O}(n^2)$ vorgeschlagen.

\section{Prioritätsansatz}

Mit dem Prioritätsansatz wird für ein Ziel $z_i$ die Dringlichkeit bestimmt, dieses als nächstes einzuholen. Hierfür fließen unterschiedliche Faktoren für die Berechnung der Priorität mit ein. Die Priorität wird nach jedem Abfangen eines Ziels neu berechnet. Mit den Faktoren $\varphi_1$, $\varphi_2$ und $\varphi_3$, wobei $\varphi_i\in\mathbb{R}$, wird die Priorität eines Ziels berechnet. In die jeweilige Berechnung fließen die Gewichte
\begin{align*}
\omega = (w_1, w_2 ,w_3)~|~w_i \in\mathbb{R}.
\end{align*}
mit ein, um den jeweiligen Anteil an der Priorität zu erhöhen bzw. zu verringern.\\
%-------------------------Faktoren------------------------------- 
Der Geschwindigkeitsfaktor $\phi_1$ erhöht Priorität eines schnellen Ziels $z_i$ und wird mit 
\begin{align}
\varphi_1(z_i, w_1) = \frac{|v_i|}{v_{verfolger}}\cdot w_1.
\end{align}\\
berechnet.
\label{def:FaktorPos}
Der Positionsfaktor $\phi_2$ erhöht Priorität bei Zielen, die sich vom Ursprung wegbewegen, andernfalls verringert sich die Priorität. Dies wird mit dem Faktor $a\in\{-1,1\}$ verrechnet.
\begin{align}
\varphi_2(z_i, w_2) = \frac{|p_i|}{v_{verfolger}}\cdot a \cdot w_2.
\end{align}\\
%\begin{definition}
%\textcolor{red}{TODO: Sicherstellen, dass diese Def. notwendig ist, ich vermute nein}\\
%Der Schnittpunktsfaktor $\phi_3$ verringert die Priorität bei Zielen in der Nähe des %Schnittpunktes und ist definiert durch
%\begin{align*}
%\phi_3(z_i, w_3) = \bigg\vert\frac{\|0,p_i\|_1}{0-v_i}\bigg\vert \cdot w_3 \text{~~~~~~~~~~~~~~~~(siehe Definition \ref{def:WegZeit})}.
%\end{align*}
%Diese Definition scheint im Konflikt mit Definition \ref{def:FaktorPos} zu stehen. Allerdings %fördert die Kombination aus den beiden Definitionen weit entfernte Ziele und solche, von denen %man schnell die anderen Achsen erreichen kann.
%\end{definition}
%\begin{definition}
%\textcolor{red}{TODO: Sicherstellen, dass diese Def. notwendig ist, ich vermute nein}\\
%Der Ursprungsfaktor $\phi_4$ erhöht die Priorität bei Zielen Nahe des Ursprungs geringfügig und %ist definiert durch
%\begin{align*}
%\phi_4(z_i, w_4) = \bigg\vert\frac{\|p_{ursprung},p_i\|_1}{0-v_i}\bigg\vert \cdot w_4 
%\text{~~~~~(siehe Definition \ref{def:WegZeit})}.
%\end{align*}
%\end{definition}
Der Distanzfaktor $\varphi_3$ verringert die Priorität bei großen Abständen zur aktuellen Position und wird auf Grundlage der Definition \ref{def:WegZeit} berechnet mit
\begin{align}
\varphi_3(z_i, w_3) = \bigg\vert\frac{\|p_{verfolger},p_i\|_1}{v_{verfolger}-v_i}\bigg\vert \cdot w_3.
\end{align}
%\alpha(z_i, \omega) = \varphi_1(z_i,w_1) + \varphi_2(z_i,w_2) - \varphi_3(z_i,w_3) - \varphi_4(z_i,w_4) - \varphi_5(z_i,w_5)
\begin{definition}
Die Priorität $\alpha_i\in\mathbb{R}$ eines Ziels $z_i$ bestimmt die Wichtigkeit eines Ziels, als nächstes eingeholt zu werden und wird mit
\begin{align*}
\alpha_i(z_i, \omega) = \varphi_1(z_i,w_1) + \varphi_2(z_i,w_2) - \varphi_3(z_i,w_3)
\end{align*}
definiert.
\end{definition}\noindent
Die einzelnen Ziele werden nun in eine Prioriätätswarteschlange
\begin{align*}
\mathcal{Q} = T\subseteq Z.
\end{align*}
eingesetzt. Diese wird in absteigender Reihenfolge nach $\alpha_i$ sotiert. In jeder Iteration wird die Priorität neu berechnet, sodass $\mathcal{Q}$ ebenfalls neu sortiert wird.

\section{Algorithmus mit dem Prioritätsansatz}

In diesem Abschnitt wird ein konkreter 20A-Fall-Algorithmus vorgestellt. Während der 1D-Algorithmus aus \cite{helvig} einmalig durch jeden Zustand iteriert, wird in diesem Algorithmus immer für das erste Element $current$ aus der Prioritätswarteschlange $\mathcal{Q}$ eine Abfolge von Operationen durchgeführt. \\
Zunächst wird überprüft, ob sich inklusive $current$ alle verbleibenden Ziele auf einer Seite des Ursprungs befinden. Dabei muss gelten, dass die Ziele sich zu dem Zeitpunkt auf einer Seite befinden müssen, zu dem der Verfolger den Schnittpunkt erreicht hat. Das Abfangen der verbleibenden Ziele und die Rückkehr zum Ursprung ist dabei einfach zu berechnen. Dies stellt die Abbruchbedingung des Algorithmus dar und ist spätestens mit dem letzten Ziel erfüllt. Ist die Bedingung nicht erfüllt, wird für jedes verbleibende Ziel die Priorität $\alpha$ neu berechnet und in $\mathcal{Q}$ absteigend nach $\alpha$ neu sortiert. 
Anschließend wird die Zeit $\pi[prev\rightarrow current]$ vom vorherigen Ziel $prev$ bis $current$ berechnet und auf den aktuellen Zeitstempel addiert. Anschließend wird mit der ermittelten Zeit die Position jedes Ziels in $\mathcal{Q}$ gemäß Definition \ref{def:UpdatedPos} aktualisiert. 
Nun werden neben $current$ alle Ziele, welche zwischen $prev$ und $current$ abgefangen wurden, aus $\mathcal{Q}$ entfernt und ein Output-Array $OUTPUT$ eingefügt. Dies wird dann solange bis zum Abbruchkriterium fortgeführt. Am Ende wird dann $OUTPUT$ in der Reihenfolge des Abfangens sortiert und zurückgegeben. Der Algorithmus ist formal beschrieben in Algorithmus \ref{alg:2OA.1}.

\begin{minipage}{1\linewidth}
\begin{algorithm}[H]
\begin{algorithmic}
\floatname{algorithm}{Algorithmus}
\caption{Prioritäts-Algorithmus für zwei-orthogonale Achsen beim bewegende Ziele in TSP}
\label{alg:2OA.1}
\State \textbf{Input:} Ziele $Z$, Ursprung $z_{ursprung}$, Verfolgergeschwindigkeit $v_{max}$
\State \textbf{Output:} Ziele $Z$ in der Tour-Reihenfolge, inklusive Retour zum Ursprung\\

\State Sei \emph{t} das Zeit-Array, welches für jedes $z_i\in Z$ die Abfangzeit angibt
\State Sei \emph{current} das Ziel, welches der Verfolger soeben eingeholt hat
\State Sei \emph{OUTPUT} die Liste an Zielen in der Abfangreihenfolge
\State $current\leftarrow ursprung$
\State $OUTPUT.add(current)$
\State $\mathcal{Q} \leftarrow$ Prioritätswarteschlange mit Zielen, welche diese in absteigender Reihenfolge nach ihrer Priorität sortiert. 

\For {$z_i\in Z$}
\State $t[z_i] \leftarrow \infty$
\State $\mathcal{Q}.add(z_i)$
\State Berechne $\alpha(z_i)$
\EndFor\\

\While {$\mathcal{Q}$ beinhaltet verbleibende Ziele}
\If {jedes verbleibende Ziel liegt auf einer der vier Seiten des Schnittpunktes}
\For {$z_i\in \mathcal{Q}$}
\State $t[z_i] \leftarrow$ Zeit von der aktuellen Position bis zum Abfangen von $z_i$
\EndFor
\State Berechne Rückkehr zum Ursprung von dem Ziel, welches als letztes aus $\mathcal{Q}$
\State erreicht wird
\State $OUTPUT.addAll(\mathcal{Q})$
\State break
\EndIf \\

\State Berechne $\alpha(z_i),~\forall z_i\in\mathcal{Q}$ und update $\mathcal{Q}$
\State $prev\leftarrow current$
\State $current \leftarrow \mathcal{Q}.poll()$
\State $t[current] \leftarrow time[prev] + \pi[prev\rightarrow current]$
\State $OUTPUT.add(current)$
\State Update die Position von jedem $z_i\in\mathcal{Q}$
\State $eingeholteZiele \leftarrow$ Ziele zwischen $prev$ und $current$
\State $\mathcal{Q}.removeAll(eingeholteZiele)$
\State $OUTPUT.addAll(eingeholteZiele)$
\EndWhile\\

\State Sortiere $eingeholteZiele$ in aufsteigender Reihenfolge nach $t[z_i]$
\State return $OUTPUT$
\end{algorithmic}
\end{algorithm}
\end{minipage}



\subsection{Laufzeitkomplexität Prioritätsansatz}

Der Prioritätsansatz geht mit der Prioritätswarteschlange linear jedes Ziel maximal einmal durch. Wird ein Ziel zwischen dem vorherigem und dem aktuell betrachteten eingeholt, wird dieses direkt aus der Warteschlange entfernt. 
Für die Überprüfung auf abgefangene Ziele ergibt sich eine Zeitkomplexität von $\mathcal{O(n)}$, da diese für alle verbleibenden Ziele aus der Warteschlange durchgeführt wird. Die selbe Komplexität ergibt sich für das Updaten der Prioritäten. Die Berechnung der Zeit zum Einholen eines Ziels erfolgt in $\mathcal{O(1)}$ (siehe Definition \ref{def:WegZeit}). Die Überprüfung auf die Abbruchbedingung beläuft sich auf eine Laufzeit von $\mathcal{O(n)}$, da dies für alle verbleibenden Ziele überprüft wird, ob sich diese auf der selben Seite befinden. Ist dem so, wird für jedes Ziel die finale Zeit und anschließend die Rückkehr zum Ursprung in konstanter Zeit berechnet. In Kombination mit dem Iterieren durch die Warteschlange werden die soeben genannten Laufzeiten um den Faktor $n$ erhöht. Jegliche Sortierungen befinden sich außerhalb der Warteschlange und haben mit einem gängigen Sortierverfahren \cite{kaaser2014algorithmen} eine Zeitkomplexität von $\mathcal{O(n\log(n))}$. \\
Somit ergibt sich beim Prioritätsalgorithmus eine Gesamtzeitkomplexität von $\mathcal{O(n^2)}$.

\subsection{Korrektheit Prioritätsansatz}
Bei der Korrektheit des Prioritätsansatzes ist die Bedingung wichtig, dass der Algorithmus nicht unbedingt ein optimales Ergebnis liefert. Dieser betrachtet nach jedem Abfangen eines Ziels jedes verbliebene Ziel und updatet deren neue Priorität. Die Gewichte für die Prioritätsberechnung können dabei willkürlich gewählt werden, allerdings empfiehlt sich ein geeignetes Set zu wählen, um eine schnelle Tour zu ermöglichen. In jeder Iteration wird dabei das Ziel mit der höchsten Priorität ausgewählt und abgefangen. Sofern ein Ziel bereits zwischen zwei anderen eingeholt wurde, wird dieses aus der Warteschlange entfernt. In der Abbruchbedingung befinden sich alle Ziele auf der selben Seite, dieser Teil ist einfach zu berechnen und garantiert die schnnellstmögliche Abfolge am Ende der Tour. In jedem Fall wird eine Tour zurückgegeben, dessen Reihenfolge von den gewählten Gewichten abhängig ist.

\section{Brute-Force für zwei orthogonale Achsen im MT-TSP}

Der Prioritätsansatz liefert zwar eine effiziente und schnelle Lösung, garantiert aber keine optimalen Ergebnisse. Um die genaue Güte zu bestimmen, ist ein optimaler Algorithmus nötig. Zwar ist dieser für große Eingaben nicht zu gebrauchen, dennoch empfiehlt sich in diesem Fall die Brute-Force-Methode, um den Algorithmus abschätzen zu können. \\
Mit einem Brute-Force werden alle Möglichkeiten durchprobiert, um eine Lösung zu bestimmen, in unserem Fall die optimale Tour. Dafür wird für die Zielliste des Inputs alle Permutationen erstellt. Um alle Permutationen zu bestimmen, wird ein Permutationsbaum generiert. Dieser beginnt bei der Wurzel, wobei für diese auch der Ursprung direkt eingesetzt werden kann. Anschließend wird jedes Ziel als Kind des Wurzelknotens eingesetzt. Die Kinder wiederum bekommen weitere $k-1$ Ziele als Kinderknoten, wobei $k$ die Tiefe des Baumes darstellt. Damit wird sichergestellt, dass keine Ziele in einer Tour doppelt vorkommen und damit, statt $10^{10}$, $n!$ Permutationen generiert werden. Mit dieser Variante wird bei $n$ Zielen insgesamt eine Anzahl von $V_n = n + n\cdot (V_{n-1})$ Knoten in den Baum eingefügt. Dies kann mittels Rekursion einfach berechnet werden. Für $10$ Ziele wären dies also $9.864.100$ Einträge.\\
Anschließend kann für jede der Permutationen die Tour bestimmt werden. Nachdem durch alle der Permutationen iteriert wurde, ist die Permutation mit der kürzesten Tourzeit die optimale Tour. Dabei zu beachten ist, dass es mehrere optimale Touren geben kann, die Tourzeit hingegen bleibt jeweils gleich. Gerade bei wenigen Zielen ist die Anwendung zu empfehlen, da beispielweise der Input $Z=\{z_1, z_2, z_3\}$ nur 6 Kombinationen durchrechnen muss (siehe Abbildung \ref{fig:BF1}). Wie bereits erwähnt ist die Brute-Force bei Eingaben mit vielen Zielen nicht zu empfehlen. Bereits mit $n=10$ Zielen gibt es $10! = 3.628.800$ Permutationen, die alle ausprobiert werden müssen. Um dem Abhilfe zu verschaffen, kann der Permutationsbaum an vielen Stellen beschnitten werden, sodass große Teile gar nicht erst berechnet werden müssen. Betrachten dafür zwei Szenarien an einer Permutation bis zum Index $k$.
\begin{enumerate}
\item
Sei $\tau_{min}$ die aktuell schnellste Tourzeit einer Permutation. Der Baum wird nun unterhalb von $k$ beschnitten, sofern das Ziel $z_k$ bereits eine größere Tourzeit benötigt, als $\tau_{min}$. 

\item
Überprüfe, ob zwischen dem vorherigen $z_{k-1}$ und dem jetzigen Ziel $z_{k}$ eines der verbleibenden Ziele abgefangen wird. Sofern ein Ziel $z_{i}, i>k$ dabei angefangen wird, ist dies äquivalent dazu, dass eine andere Permutation existiert, in der $z_i$ vor $z_k$ eingeholt wird. Diese wird ggf. später noch berechnet und somit wird der Baum ebenfalls bei $k$ beschnitten.
\end{enumerate} 
Somit werden Permutationen mit der selben Reihenfolge an Zielen bis $k$ ausgelassen, da diese keine optimale Route erzeugen werden. Zusätzlich kann der Algorithmus in den meisten Fällen mit einer Sortierung nach der Geschwindigkeit in absteigender Reihenfolge verbessert. Oftmals wird damit schnell ein gutes $\tau_{min}$ gefunden und damit werden umso mehr Pfade abgeschnitten. Darüber hinaus könnte ebenfalls ein Prioritätsmaß genutzt werden, ist aber nicht notwendig.
Mit diesen Bedingungen wird im Beipiel von Abbildung \ref{fig:BF1} $2$ Berechnungen eingespart (siehe Abbildung \ref{fig:BF2}). Bei jeder Permutation wird am Anfang und am Ende der Ursprung eingerechnet. Formal zusammengefasst wird der Brute-Force-Algorithmus in Algorithmus \ref{alg:BF}.

\newpage

\begin{figure}[htbp]
\centering
\begin{tikzpicture}[->,level/.style={sibling distance = 5cm/#1,
  level distance = 1.5cm}]
\node[rectangle, draw, rounded corners=5] (root) {Wurzel}
	child { node[red]{$z_1$}
		child { node[blue]{$z_2$}
			child { node[green](1){$z_3$} }
		}
		child { node[green]{$z_3$}
			child { node[blue](2){$z_2$} }
		}
	}
	child { node[blue]{$z_2$}
		child { node[red]{$z_1$}
			child { node[green](3){$z_3$} }
		}
		child { node[green]{$z_3$}
			child { node[red](4){$z_1$} }
		}
	}
	child { node[green]{$z_3$}
		child { node[red]{$z_1$}
			child { node[blue](5){$z_2$} }
		}
		child { node[blue]{$z_2$}
			child { node[red](6){$z_1$} }
		}
	};	
\node[above of=root, yshift=-1cm, xshift=1.5cm] {$\tau_{min} = 6$};
\node[below of=1, yshift=0.35cm] {$\tau_{z_1,z_2,z_3 = 8,5}$};
\node[below of=2, yshift=0.35cm] {$\tau_{z_1,z_3,z_2 = 6}$};
\node[below of=3, yshift=0.35cm] {$\tau_{z_2,z_1,z_3 = 9}$};
\node[below of=4, yshift=0.35cm] {$\tau_{z_2,z_3,z_1 = 12}$};
\node[below of=5, yshift=0.35cm] {$\tau_{z_3,z_1,z_2 = 18}$};
\node[below of=6, yshift=0.35cm] {$\tau_{z_3,z_2,z_1 = 11}$};
\end{tikzpicture}
\caption{Die Berechnung der jeweiligen (Teil-)Tourzeit $\tau_{i}, ~1\leq i\leq n!$ ist in diesem Fall bei nur $n!=3!=6$ Permutationen noch problemlos.}
\label{fig:BF1}
\end{figure}

\begin{figure}[htbp]
\centering
\begin{tikzpicture}[->,level/.style={sibling distance = 5cm/#1,
  level distance = 1.5cm}]
\node[rectangle, draw, rounded corners=5] (root) {Wurzel}
	child { node[red]{$z_1$}
		child { node[blue]{$z_2$}
			child { node[green]{$z_3$} }
		}
		child { node[green]{$z_3$}
			child { node[blue]{$z_2$} }
		}
	}
	child { node[blue]{$z_2$}
		child { node[red]{$z_1$}
			child { node[green]{$z_3$} }
		}
		child { node[green]{$z_3$}
			child { node[red]{$z_1$} }
		}
	}
	child { node[green](z3){$z_3$}
		child { node[gray]{$z_1$}
			child { node[gray]{$z_2$} }
		}
		child { node[gray]{$z_2$}
			child { node[gray]{$z_1$} }
		}
	};	
\node[above of=root, yshift=-1cm, xshift=1.5cm] {$\tau_{min} = 6$};
\node[below of=1, yshift=0.35cm] {$\tau_{z_1,z_2,z_3 = 8,5}$};
\node[below of=2, yshift=0.35cm] {$\tau_{z_1,z_3,z_2 = 6}$};
\node[below of=3, yshift=0.35cm] {$\tau_{z_2,z_1,z_3 = 9}$};
\node[below of=4, yshift=0.35cm] {$\tau_{z_2,z_3,z_1 = 12}$};
\node[right of=z3, xshift=0.2cm] {$\tau_{z_3} = 6.5$};
\node[red, thick, cross out, below, xshift=4.3cm, yshift=-2.1cm, rotate=50] { };
\node[red, thick, cross out, below, xshift=5.7cm, yshift=-2.1cm, rotate=-50] { };
\end{tikzpicture}
\caption{Mit der Brute-Force-Optimierung wird direkt hinter $z_3$ abgeschnitten, da an diesem Knoten bereits der Zeitpunkt $\tau_{min}$ überschritten wird.}
\label{fig:BF2}
\end{figure}

\begin{minipage}{1\linewidth}
\begin{algorithm}[H]
\begin{algorithmic}
\floatname{algorithm}{Algorithmus}
\caption{Brute-Force-Algorithmus für zwei-orthogonale Achsen beim bewegende Ziele in TSP}
\label{alg:BF}
\State \textbf{Input:} Ziele $Z$, Ursprung $z_{ursprung}$, Verfolgergeschwindigkeit $v_{max}$
\State \textbf{Output:} Ziele $Z$ in der Tour-Reihenfolge, inklusive Retour zum Ursprung\\

\State $B\rightarrow$ Permutationsbaum, bei $n$ Zielen muss es $n$ Kinderknoten geben.
\State $\tau_{min}\leftarrow \infty$
\State Sei $aktuelleZiele$ das Array mit den aktuellen Indizes von $Z$, initialisiert mit einsen
\State Sei $k$ die aktuelle Tiefe im Baum
\State Sei $t$ das Zeit-Array welches für die aktuelle Ziel-Reihenfolge die Abfangzeit angibt
\State $k\leftarrow 1$

\While {$aktuelleZiele[0]\leq n$ und $aktuelleZiele[n]\leq n$}
\State $current\leftarrow Z[aktuelleZiele[k]]$
\State $prev\leftarrow Z[aktuelleZiele[k-1]]$
\State $t[current] \leftarrow t[prev] + \pi[prev\rightarrow current]$
\If {$t[current]\geq \tau_{min}$ oder mindestens ein Ziel der verbliebenen Indizes wird zwischen\\~~~~~~~ $current$ und $prev$ abgefangen}
\If {$aktuelleZiele[k]=n$}
\State Dekrementiere $k$
\State Inkrementiere $aktuelleZiele[k]$
\Else
\State Inkrementiere $aktuelleZiele[k]$ 
\EndIf
\Else
\If {$k<n$}
\State Inkrementiere $k$
\Else
\State $t[current]\leftarrow t[current] + \pi[current\rightarrow ursprung]$ 
\If {$t[current] < \tau_{min}$}
\State $\tau_{min}\leftarrow t[current]$
\State Dekrementiere $k$
\State Inkrementiere $aktuelleZiele[k]$
\EndIf 
\EndIf
\EndIf
\EndWhile
\end{algorithmic}
\end{algorithm}
\end{minipage}

\subsection{Laufzeitkomplexität Brute-Force-Ansatz}
%Im worst case wird nichts oder erst ganz am Ende der Baum beschnitten, wodurch bei einem großen $n$ die Laufzeit
Zunächst wird die benötigte Laufzeit zur Erstellung des Baums betrachtet. Dafür werden $V_n = n + n\cdot (V_{n-1})$ Knoten eingefügt. Die Generierung des Baums kann demnach mit $\mathcal{O}(n!)$ abgeschätzt werden. \\
Trotz der zuvor vorgeschlagenen Verbesserungen des Brute-Force-Algorithmus muss der worst-case betrachtet werden. Dabei wird der Baum an keiner Stelle wegen der Tourzeit-Bedingung  beschnitten, da $\tau_{min}$ nach jeder Permutation kleiner wird. Der Fall ist zwar sehr unwahrscheinlich, aber möglich. Dies würde in eine Laufzeitkomplexität von $\mathcal{O}(n!)$ resultieren. Allerdings werden mit der 2. Bedingung definitiv Teile des Baumes abgeschnitten, da immer Ziele zwischen den einzelnen Zielen eingeholt werden\footnote{Dies gilt für $n>2$}. An sich benötigt die Berechnung eine Laufzeit von $\mathcal{O}(n^2)$, schneidet dafür aber große Teile des Baums weg. Es hat sich gezeigt, dass bei den eigentlichen $n!$ Permutationen meistens weniger als $5\%$ der Permutationen letztendlich ausgerechnet werden\footnote{Später dazu mehr im Kapitel Experimente}. \\
Nach verschiedenen worse-case-Analysen hat sich schlussendlich gezeigt, dass die Erstellung des Permutationsbaums mit Abstand die größte Laufzeit einbüst. Somit hat der Brute-Force-Algorithmus eine Zeitkomplexität von $\mathcal{O}(n!)$.


\subsection{Korrektheit Brute-Force-Ansatz}
Mit dem Brute-Force-Algorithmus wird jede mögliche Permutation an Zielen ausprobiert. Bei der Berechnung einer Permutation werden einfach alle Ziele nacheinander abgefangen und der Zeitstempel mit der Zeit erhöht, die zum Abfangen des jeweiligen Ziels benötigt wird. Sofern eine Permutation schneller als die aktuell schnellste, wird diese übernommen und $\tau_{min}$ mit der benötigten Tourzeit überschrieben. Mit den Verbesserungen wird der Permutationsbaum beschnitten und es werden Berechnungen eingespart. Somit wird garantiert, dass die optimale Tour zurückgegeben wird.


\chapter{Experimente}
\textcolor{red}{TODO} 

\chapter{Gegenbeispiel Algorithmus von Helvig et. al.}

Dieses Kapitel dient temporär als Gegenbeispiel für den Algorithmus Helvig et. al. 
Input: 
\begin{itemize}
\item
Ziele $Z=\{(-933,13),(-883,-6),(-203,-12),(756,8)\}$\\
\textcolor{red}{(Die Zahlen der Ziele sind zufällig generiert, also nicht wundern)}
\item
Verfolger $\kappa=(0,15)$
\end{itemize}
Damit befinden sich drei Ziele auf der linken und eines auf der rechten Seite des Ursprungs.
\textcolor{red}{TODO: Wenn Gegenbsp korrekt, erstelle Grafik}\\
Mit dem Algorithmus von Helvig et. al. würden nun folgende 6 Zustände erstellt werden:
\begin{align*}
&A_0 \\
&A_1 = \{(-203, -12), (756, 8)\}\\
&A_2 = \{(756, 8), (-203, -12)\}\\
&A_3 = \{(-883, -6), (756, 8)\}\\
&A_4 = \{(756, 8), (-883, -6)\}\\
&A_5 = \{(-933, 13), (756, 8)\}\\
&A_6 = \{(756, 8), (-933, 13)\}\\
&A_{final} 
\end{align*}
Nun wird durch jeden dieser Zustände in chronologischer Reihenfolge iteriert. Dabei ergeben sich für die jeweiligen Zustände folgende Zeiten:
\begin{align*}
&\text{Iteration 0:}~t=[0.0, 67.67, 108.0, \infty, \infty, \infty, \infty, \infty] \\
&\text{Iteration 1:}~t=[0.0, 67.67, 108.0, 98.11, 398.0, \infty, \infty, \infty] \\
&\text{Iteration 2:}~t=[0.0, 67.67, 108.0, 98.11, 398.0, \infty, \infty, 2079.33] \\
&\text{Iteration 3:}~t=[0.0, 67.67, 108.0, 98.11, 398.0, 1005.17, 528.48, 2079.33] \\
&\text{Iteration 4:}~t=[0.0, 67.67, 108.0, 98.11, 398.0, 1005.17, 528.48, 1737.78] \\
&\text{Iteration 5:}~t=[0.0, 67.67, 108.0, 98.11, 398.0, 1005.17, 528.485, 1737.78]
\end{align*}
Bemerke, dass keine Iteration $7$ nötig ist, da nach $A_{final}$ keine Ziele mehr abgefangen werden müssen. Mit der Iteration $6$ gab es keine weiteren Änderungen, kann also auch weggelassen werden. Somit hat die vermeintlich optimale Tour eine Dauer von $1737.78$-Zeiteinheiten. Dabei werden die Ziele in folgender Reihenfolge abgefangen:
\begin{align*}
(0,0),~ &\text{Abfangzeit}: 0.0 \\
(-933, 13),~ &\text{Abfangzeit}: 33.32 \\
(-203, -12),~ &\text{Abfangzeit}: 67.66 \\
(756, 8),~ &\text{Abfangzeit}: 398.0 \\
(-883, -6),~ &\text{Abfangzeit}: 1199,22 \\
(0, 0),~ &\text{Abfangzeit}: 1727,78 
\end{align*}

Wendet man nun den Brute-Force-Algorithmus erhält man folgende Reihenfolge der Ziele:
\begin{align*}
(0, 0),~ &\text{Abfangzeit}: 0.0 \\
(-933, 13),~ &\text{Abfangzeit}: 33.32 \\
(-203, -12),~ &\text{Abfangzeit}: 67.66 \\
(-883, -6),~ &\text{Abfangzeit}: 98.11 \\
(756, 8),~ &\text{Abfangzeit}: 528.48 \\
(0, 0),~ &\text{Abfangzeit}: 860.73 \\
\end{align*}
Zunächst würde man vermuten, dass der Algorithmus von Helvig et. al. nicht korrekt implementiert wurde. Dies kann man anhand dieses Beispiels wiederlegen. \\
Nach dem Algorithmus wird der Graph $G$ in topologischer Reihenfolge erstellt. Dabei gibt es nur Übergänge in Zustände mit einem Summenwert der Indizes, der genau ein höher ist, als der Summenwert des jetzigen Zustandes. Betrachten nun das nicht so ganz offensichtliche Problemziel $Z_P=(-993, 13)$. Dieses liegt in den Zuständen $A_6$ und $A_7$, welche sich damit in $G$ an letzter Stelle vor $A_{final}$ befinden. In der optimalen Tour liegt der erste Wendepunkt bei dem Ziel $(-883, -6)$ und fängt dabei $(-993, 13)$ und $(-203,-12)$ ab. Der eindimensionalen Algorithmus überprüft hingegen nicht auf Zustände bzw. Ziele, welche auf dem Weg zum Wendepunkt liegen. Diese werden erst im \emph{Postprocessing}-Schritt hinzugefügt. Somit wird $Z_P$ im Graphen erst ganz am Ende berechnet. Dabei dauern alle Pfade zu lange, sodass sich $Z_P$ inzwischen sehr weit entfernt vom Ursprung befindet. \\\\
Dies lässt sich relativ simpel lösen, indem eben genau diese Zustände berechnet werden, bei denen das jeweilige $s_k$ zwischen Wendepunkten eingeholt wird. Diese Zustände werden markiert und wenn eine Verbindung zu diesem Zustand berechnet wurde, werden die maximal 2 nachfolgenden Zustände berechnet. Befindet sich die Iteration bei einem markierten Zustand, wird dieser übersprungen. Zwar erhöhen sich die Berechnungen für einen Zustand ggf., die Gesamtberechnungen bleiben wiederum gleich. Dies lässt sich algorithmisch allerdings nur in $\mathcal{O}(n^3)$ lösen. Mit Sicherheit gibt es eine elegantere Lösung, bei der Laufzeitkomplexität von $\mathcal{O}(n^2)$ bleibt der Algorithmus damit vermutlich nicht mehr.

%\chapter{Conclusion}
\chapter{Zusammenfassung und Ausblick}
\textcolor{red}{TODO: Zusammenfassung der Ergebnisse, v.a. aus Experimente} 
%-------------------Ergebnisse der Arbeit--------------------

\noindent
%----------------------Verbesserungen------------------------
Zwar wurden die Probleme bei der Modellierung als Graphen aufgezeigt, ausgeschlossen sei diese allerdings nicht. Mit dem Ansatz über das Lemma \ref{lem:1} sollte eine optimale Strategie definitiv möglich sein und eine geringere Laufzeit aufweist, als der Brute-Force-Algorithmus mit $\mathcal{O}(n!)$. Der Brute-Force-Ansatz kann zudem um einiges verbessert werden, indem der Permutationsbaum bereits bei der Generierung die einzelnen Ziele berechnet. Somit werden viele Permutationen gar nicht erst erstellt. Zwar wird damit eine deutlich bessere Laufzeit erzielt, bei worst-case-Fällen mit Eingaben von $n>10$ ist Brute-Force allerdings weiterhin untauglich.\\
%-------------------------Ausblick---------------------------
Mit dem Prioritätsansatz wurde zum Einen ein effizienter und mit dem Brute-Force-Ansatz zum Anderen ein optimaler Algorithmus für wenig Ziele vorgestellt. Als nächstes Schritt wäre ein einigermaßen effizienter, aber optimaler Algorithmus vom großen Interesse. Dies wäre ein notwendiger Schritt, um theoretische Arbeit für $k$-Achsen in MT-TSP zu leisten. Darüber hinaus ist das nächste Ziel in dieser Thematik die Betrachtung von zweidimensionalen MT-TSP und das Aufstellen von Heuristiken.
Diesen Jahres wurde für generelle Fälle eine Arbeit\cite{moraes} veröffentlicht, in der mit evolutionären Strategien versucht wird, auf eine optimale Tour in vielen Iterationen hinzuarbeiten. Dabei ist allerdings die optimale Tour von vielen verschiedenen Parametern abhängig und garantieren auch keine optimale Lösung. 



\begin{bibtex-entries}
@article{helvig,
  title={The moving-target traveling salesman problem},
  author={Helvig, Christopher S and Robins, Gabriel and Zelikovsky, Alex},
  journal={Journal of Algorithms},
  volume={49},
  number={1},
  pages={153--174},
  year={2003},
  publisher={Elsevier}
}

@article{moraes,
  title={Experimental Analysis of Heuristic Solutions for the Moving Target Traveling Salesman Problem Applied to a Moving Targets Monitoring System},
  author={de Moraes, Rodrigo S and de Freitas, Edison P},
  journal={Expert Systems with Applications},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{hammar,
  title={Approximation results for kinetic variants of TSP},
  author={Hammar, Mikael and Nilsson, Bengt J},
  booktitle={International Colloquium on Automata, Languages, and Programming},
  pages={392--401},
  year={1999},
  organization={Springer}
}

@incollection{brandstadt1994kurzeste,
  title={K{\"u}rzeste Wege},
  author={Brandst{\"a}dt, Andreas},
  booktitle={Graphen und Algorithmen},
  pages={106--123},
  year={1994},
  publisher={Springer}
}

@article{kaaser2014algorithmen,
  title={Algorithmen und Datenstrukturen},
  author={Kaaser, Dominik S},
  year={2014}
}
\end{bibtex-entries}

% If you need to have an appendix (I advise against it), insert it
% here using, first, \appendix and then \chapter and then,
% possibly, \section. 
%
\appendix
\chapter{Implementierungen}




% \section{Experimental Parameters} % possibly
%
% Again, I advise against using an appendix.


\end{document}
